{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "af45a887",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Imports\n",
    "import os\n",
    "os.environ[\"OMP_NUM_THREADS\"] = '1'\n",
    "import pandas as pd\n",
    "import scipy.stats as stats\n",
    "import seaborn as sns\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "from sqlalchemy.types import *\n",
    "from sqlalchemy.engine import create_engine\n",
    "import pymysql\n",
    "from sqlalchemy_utils import create_database, database_exists\n",
    "import time\n",
    "import json\n",
    "\n",
    "from tqdm import tqdm\n",
    "import tmdbsimple as tmdb"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "fff14864",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['akas_filtered.csv.gz',\n",
       " 'basics_filtered.csv.gz',\n",
       " 'final_tmdb_data_2000.csv.gz',\n",
       " 'final_tmdb_data_2001.csv.gz',\n",
       " 'ratings_filtered.csv.gz',\n",
       " 'tmdb_api_results_2000.json',\n",
       " 'tmdb_api_results_2001.json',\n",
       " 'tmdb_api_results_2010.json',\n",
       " 'tmdb_results_combined.csv.gz']"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "FOLDER = \"Data/\"\n",
    "os.makedirs(FOLDER, exist_ok=True)\n",
    "os.listdir(FOLDER)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "e5b2dd8b",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "dict_keys(['username', 'password'])"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pymysql.install_as_MySQLdb()\n",
    "import json\n",
    "with open('C:/Users/Mikey.Windows/Documents/keys/keys.json') as f:\n",
    "    login1 = json.load(f)\n",
    "login1.keys()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "eb302405",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "dict_keys(['api-key'])"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "with open('C:/Users/Mikey.Windows/Documents/keys/tmdb_api.json') as f:\n",
    "    login2 = json.load(f)\n",
    "login2.keys()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "f891abcc",
   "metadata": {},
   "outputs": [],
   "source": [
    "tmdb.API_KEY=login2['api-key']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "6bcf1846",
   "metadata": {},
   "outputs": [],
   "source": [
    "connection =f\"mysql+pymysql://{login1['username']}:{login1['password']}@localhost/movies\"\n",
    "engine = create_engine(connection)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "1b3c222a",
   "metadata": {},
   "outputs": [],
   "source": [
    "if not database_exists(connection):\n",
    "    create_database(connection)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "f591c698",
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_movie_with_rating(movie_id):\n",
    "    \"\"\"Adapted from source = https://github.com/celia/tmdbsimple\"\"\"\n",
    "    #Get Movie IDS\n",
    "    movie=tmdb.Movies(movie_id)\n",
    "    #Get Movie detailed info\n",
    "    info=movie.info()\n",
    "    #Movie Release info\n",
    "    releases=movie.releases()\n",
    "    #Iterate over the countires in releases data\n",
    "    for c in releases['countries']:\n",
    "        if c['iso_3166_1'] =='US':\n",
    "            #Update cert\n",
    "            info['certification'] = c['certification']\n",
    "    return info"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "e02615ba",
   "metadata": {},
   "outputs": [],
   "source": [
    "def write_json(new_data, filename): \n",
    "    \"\"\"Appends a list of records (new_data) to a json file (filename). \n",
    "    Adapted from: https://www.geeksforgeeks.org/append-to-json-file-using-python/\"\"\"  \n",
    "    #Open Json file in read write\n",
    "    with open(filename,'r+') as file:\n",
    "        #Load exsiting file data\n",
    "        file_data = json.load(file)\n",
    "        #Check Check if new_data and file_data are lists.\n",
    "        if isinstance(new_data, list) & isinstance(file_data, list):\n",
    "            file_data.extend(new_data)\n",
    "        else:\n",
    "             file_data.append(new_data)\n",
    "        #Move the file to beginning of file.        \n",
    "        file.seek(0)\n",
    "        #Write it\n",
    "        json.dump(file_data, file)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "af8286a7",
   "metadata": {},
   "outputs": [],
   "source": [
    "YEARS_TO_GET=[2010,2011]\n",
    "errors=[]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "122a5f4d",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sqlalchemy import create_engine\n",
    "\n",
    "# Assuming you have already defined the 'engine' variable with the correct connection details.\n",
    "\n",
    "# SQL command to create the 'movie_data' table\n",
    "create_table_query = \"\"\"\n",
    "CREATE TABLE movie_data (\n",
    "    tconst VARCHAR(10) PRIMARY KEY,\n",
    "    startYear INT\n",
    ");\n",
    "\"\"\"\n",
    "\n",
    "# Execute the SQL command to create the table\n",
    "with engine.connect() as connection:\n",
    "    connection.execute(create_table_query)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "3d6996c4",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "YEARS:   0%|                                                                                     | 0/2 [00:00<?, ?it/s]\n",
      "Movies from 2010: 0it [00:00, ?it/s]\u001b[A\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "- Total errors: 0\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "Movies from 2011: 0it [00:00, ?it/s]\u001b[A\n",
      "YEARS: 100%|████████████████████████████████████████████████████████████████████████████| 2/2 [00:00<00:00, 104.80it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "- Total errors: 0\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "for YEAR in tqdm(YEARS_TO_GET, desc='YEARS', position=0):\n",
    "    JSON_FILE = f'{FOLDER}tmdb_api_results_{YEAR}.json'\n",
    "    file_exists = os.path.isfile(JSON_FILE)\n",
    "    #Json exists?\n",
    "    if not file_exists:\n",
    "        # If not, create new.\n",
    "        with open(JSON_FILE, 'w') as f:\n",
    "            json.dump([{'imdb_id': 0}], f)\n",
    "\n",
    "    # Fetch movie IDs for the current year directly from the database using SQL query\n",
    "    query = f\"SELECT tconst FROM movie_data WHERE startYear = {YEAR};\"\n",
    "    movie_ids_df = pd.read_sql(query, engine)\n",
    "    movie_ids = movie_ids_df['tconst'].copy()\n",
    "\n",
    "    if file_exists:\n",
    "        #If does, load previous data.\n",
    "        previous_df = pd.read_json(JSON_FILE)\n",
    "        #Get Movie ID's that have not processed.\n",
    "        movie_ids_to_get = movie_ids[~movie_ids.isin(previous_df['imdb_id'])]\n",
    "    else:\n",
    "        #If doesn't exist, get all movie ids for the current year.\n",
    "        movie_ids_to_get = movie_ids\n",
    "\n",
    "    # Iterate over movie IDs to get movie details.\n",
    "    for movie_id in tqdm(movie_ids_to_get, desc=f'Movies from {YEAR}', position=1, leave=True):\n",
    "        try:\n",
    "            # movie details with ratings.\n",
    "            temp = get_movie_with_rating(movie_id)\n",
    "            # Write to json\n",
    "            write_json(temp, JSON_FILE)\n",
    "            # Pause to avoid bombarding the server.\n",
    "            time.sleep(0.02)\n",
    "        except Exception as e:\n",
    "            # Store errors.\n",
    "            errors.append([movie_id, e])\n",
    "    #Read final data for the year.                \n",
    "    final_year_df = pd.read_json(JSON_FILE)\n",
    "    #Save to a csv\n",
    "    final_year_df.to_csv(f\"{FOLDER}additionals_tmdb_data_{YEAR}.csv.gz\", compression=\"gzip\", index=False)\n",
    "    #Print Error Count   \n",
    "    print(f\"- Total errors: {len(errors)}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e3cf9dfa",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python (dojo-env)",
   "language": "python",
   "name": "dojo-env"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.15"
  },
  "toc": {
   "base_numbering": 1,
   "nav_menu": {},
   "number_sections": true,
   "sideBar": true,
   "skip_h1_title": false,
   "title_cell": "Table of Contents",
   "title_sidebar": "Contents",
   "toc_cell": false,
   "toc_position": {},
   "toc_section_display": true,
   "toc_window_display": false
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
